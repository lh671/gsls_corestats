---
title: "GSLS - CS1 Simple Hypothesis Testing"
author: "Liana Hardy"
date: '2020-05-04'
output: html_notebook
---

## 3. One-Sample Tests

## 3.1 Purpose and Aim

These tests are used when we have a single sample of continuous data. It is used to find out if the sample came from a parent distribution with a given mean (or median). This essentially boils down to finding out if the sample mean (or median) is “close enough” to our hypothesised parent population mean (or median).

## 3.2 Choosing a test

There are two tests that we are going to look at in this situation; the one-sample t-test, and the one-sample Wilcoxon signed rank test. Both tests work on the sort of data that we’re considering here, but they both have different assumptions.If your data is normally distributed, then a one-sample t-test is appropriate. If your data aren’t normally distributed, but their distribution is symmetric, and the sample size is small then a one-sample Wilcoxon signed rank test is more appropriate.

## 3.3 One-sample test

For each statistical test we consider there will be five tasks:
1. Setting out of the hypothesis
2. Summarise and visualisation of the data
3. Implementation of the statistical test
4. Assessment of assumptions
5. Interpreting the output and presentation of results

't.test()'          #Performs a one sample t test , Student’s t test and Welch’s t test in later sections.
'file.choose()'     # A user friendly interface for loading in data files
'qqnorm()'          # Plots a QQ plot for comparison with a normal distribution
'qqline()'          # Adds a comparison line to the QQ plot
'shapiro.test()'    # Performs a Shapiro Wilk test for normality

p-value - It gives the probability of us getting a sample such as ours if the null hypothesis were actually true.

So:
* a high p-value means that there is a high probability of observing a sample such as ours and the null hypothesis is probably true whereas
* a low p-value means that there is a low probability of observing a sample such as ours and the null hypothesis is probably not true.

It is important to realise that the p-value is just an indication and there is no absolute certainty here in this interpretation. People, however like more definite answers and so we pick an artificial probability threshold (called a significance level) in order to be able to say something more decisive. The standard significance level is 0.05 and since our p-value is smaller than this we choose to say that “it is very unlikely that we would have this particular sample if the null hypothesis were true”.

## 3.3.6 Assumptions

In order to use a t-test for this analysis (and for the results to be strictly valid) we have to make two assumptions:

1. The parent distribution from which the sample is taken is normally distributed (and as such the sample data are normally distributed themselves). It is worth noting though that the t-test is actually pretty robust in situations where the sample data are not normal. For sufficiently large sample sizes (your guess is as good as mine, but conventionally this means about 30 data points), you can use a t-test without worrying about whether the underlying population is normally distributed or not.

2. Each data point in the sample is independent of the others. This is in general not something that can be tested for and instead has to be considered from the sampling procedure. For example, taking repeated measurements from the same individual would generate data that are not independent.

Checking for normality 
 In increasing order of rigor:
 * histogram
 * Quantile-quantile plot (qq)
 * Shapiro-Wilk test
 
## 3.3.6.3 Shapiro-Wilk test

This is one of a number of formal statistical test that assess whether a given sample of numbers come from a normal distribution. It calculates the probability of getting the sample data if the underlying distribution is in fact normal. It is very easy to carry out in R. It is important to recognise that the Shapiro-Wilk test is not without limitations. It is rather sensitive to the sample size being considered. In general, for small sample sizes, the test is very relaxed about normality (and nearly all datasets are considered normal), whereas for large sample sizes the test can be overly strict, and it can fail to recognise datasets that are very nearly normal indeed.

## 3.3.6.4 Assumption Overview

In terms of assessing the assumptions of a test it is always worth considering several methods, both graphical and analytic, and not just relying on a single method.

In the fishlength example, the graphical QQ plot analysis was not especially conclusive as there was some suggestion of snaking in the plots, but the Shapiro-Wilk test gave a non-significant p-value (0.1764). Putting these two together, along with the original histogram and the recognition that there were only 30 data points in the dataset I personally would be happy that the assumptions of the t-test were met well enough to trust the result of the t-test, but you may not be…

In which case we would consider an alternative test that has less stringent assumptions (but is less powerful): the one-sample Wilcoxon signed rank test.

## 3.4.The one-sample Wilcoxon signed-rank test

This test also considers a single sample, however for this test (in contrast to the one sample t-test) we don’t have to assume that the parent distribution is normally distributed. We do still need the parent distribution (and consequently the sample) to be symmetric though. In this test we look to see if the median of the parent distributions differs significantly from a given hypothesised value (in contrast with the t-test that looks at the mean).

'wilcox.test'     # Performs a one sample wilcoxon signed rank test ,Wilcoxon test and Mann Whitney test in later sections.

## 3.4.5 Assumptions

In order to use a one-sample Wilcoxon rank-sum test for this analysis (and for the results to be strictly valid) we have to make two assumptions:

1. The parent distribution from which the sample is symmetric
2. Each data point in the sample is independent of the others. This is the same as for the t-test and is a common feature of nearly all statistical tests. Lack of independence in your data is really tough to deal with (if not   impossible) and a large part of proper experimental design is ensuring this. Whilst there are formal statistical tests for symmetry we will opt for a simple visual inspection using both a boxplot and a histogram

## The One-sample test

For example, suppose we measure the body lengths of male guppies (in mm) collected from the Guanapo River in Trinidad. We want to test whether the data support the hypothesis that the mean body is actually 20mm. We form the following null and alternative hypotheses:
*H0: The mean body length is equal to 20mm (μ=20).
*H1: The mean body length is not equal to 20mm (μ≠20).

We will use a one-sample, two-tailed t-test to see if we should reject the null hypothesis or not.
* We use a one-sample test because we only have one sample.
* We use a two-tailed t-test because we want to know if our data suggest that the true (population) mean is different - from 20mm in either direction rather than just to see if it is greater than or less than 20mm (in which case we  would use a one-tailed test).

*The data are stored in the file “CS1-onesample.csv”*

### Read this into R using the file.choose() command
```{r}
fishlengthDF<- read.csv(file = 'CS1-onesample.csv', header=T)
fishlength<-fishlengthDF$Guanapo

# file.choose() is a nice way of generating filepaths in R. Its upside is that it allows use of the familiar windows explorer window to select your file. Its downside is that it can’t be used in automated scripts.
```

The first line reads the data into R and creates an object called a dataframe. This dataframe only contains a single column of numbers called “Guanapo” (the name of the River). In most situations, and for most statistical analyses, having our data stored in a dataframe is exactly what we’d want. However, for one sample tests we actually need our data to be stored as a vector. So, the second line extracts the values that are in the Guanapo column of our fishlengthDF dataframe and creates a simple vector of numbers that we have called fishlength. This step is only necessary for one-sample tests and when we look at more complex datasets, we won’t need to do this second step at all.

### Summarise and visualise the data
```{r}
summary(fishlength)
boxplot(fishlength, main="Male Guppies", ylab="Length (mm)")
```

The data do not appear to contain any obvious errors, and whilst both the mean and median are less than 20 (18.3 and 18.8 respectively) it is not absolutely certain that the sample mean is sufficiently different from this value to be “statistically significant”, although we may anticipate such a result.

### Perform a one-sample, two-tailed t-test
```{r}
t.test(fishlength, mu=20, alternative="two.sided")

# first argument must be a numerical vector of data values - fishlength
# second argument must be a number and is the mean to be tested under the null hypothesis - mu=20
# third argument gives the type of alternative hypothesis and must be one of "two.sided","greater" or "less"
```
### Interpreting the data

1st line - name of the test
2nd line - dataset name
3rd line contain 3 key output values
* t-value is -3.5492 (we'll need this for reporting)
* there are 28 degrees of freedom (reporting)
* the p-value is 0.001387
4th line - simply states the alternative hypothesis
5th and 6th lines give the 95th confidence interval
7th, 8th and 9th line give the sample mean again (18.29655)

__A one-sample t-test indicated that the mean body length of male guppies (μ=18.29mm) differs significantly from 20mm (t=-3.55, df=28, p=0.0014).__

The above sentence is an adequate concluding statement for this test and is what we would write in any paper or report. Note that we have included (in brackets) information on the actual mean value of our group(μ=18.29mm), the test statistic (t=-3.55), the degrees of freedom (df=28), and the p-value (p=0.0014). In some journals you are only required to report whether the p-value is less than the critical value (e.g. p<0.05) but I would always recommend reporting the actual p-value obtained.

### Checking for normality 
 In increasing order of rigor:
 *histogram
 *Quantile-quantile plot (qq)
 *Shapiro-Wilk test
 
### Plot a histogram of the data
 
```{r}
hist(fishlength, breaks = 15)
```
The distribution appears to be unimodal and symmetric, and so it isn’t obviously non-normal. However, there are a lot of distributions that have these simple properties but which aren’t normal, so this isn’t exactly rigorous. Thankfully there are other, more rigorous tests.

Q-Q plot is the short for quantile-quantile plot. This diagnostic plot (as it is sometimes called) is a way of comparing two distributions. 

### Construct a Q-Q Plot of the quantiles of the data against the quantiles of a normal distribution.
```{r}
qqnorm(fishlength) # draws qq plot
qqline(fishlength) # draws line

```
What is important to know is that if the data were normally distributed then all of the points should lie on (or close to) the diagonal line in this graph. 

In this case, the points lie quite close to the line for the most part but the sample quantiles (points) from either end of the sample distribution are either smaller (below the line on the left) or larger (above the line on the right) than expected if they were supposed to be normally distributed. This suggests that the sample distribution is a bit more spread out than would be expected if it came from a normal distribution.

It is important to recognise that there isn’t a simple unambiguous answer when interpreting these types of graph, in terms of whether the assumption of normality has been well met or not and instead it often boils down to a matter of experience.
It is a very rare situation indeed where the assumptions necessary for a test will be met unequivocally and a certain degree of personal interpretation is always needed. Here you have to ask yourself whether the data are normal “enough” for you to be confident in the validity of the test.

*nb: see pdf from course for examples of what normality looks like.*

### Perform a Shapiro-Wilk Test
```{r}
shapiro.test(fishlength)
```

The 1st line gives the name of the test and the 2nd line reminds you what the dataset was called
The 3rd line contains the two key outputs from the test:
*The calculated w-value is 0.9494 (we don’t need to know this)
*The p-value is 0.1764

As the p-value is bigger than 0.05 (say) then we can say that there is insufficient evidence to reject the null hypothesis that the sample came from a normal distribution.

### The one-sample Wilcoxon signed-rank test

The one-sample Wilcoxon signed rank test allows to see if the median body length is different from a specified value. Here we want to test whether the data support the hypothesis that the median body is actually 20mm. The following null and alternative hypotheses are very similar to those used for the one sample t-test:
*H0: The median body length is equal to 20mm (μ=20).
*H1: The median body length is not equal to 20mm (μ≠20).

We will use a one-sample, two-tailed Wilcoxon signed-rank test to see if we should reject the null hypothesis or not.

```{r}
summary(fishlength)
boxplot(fishlength, main="Male Guppies", ylab="Length (mm)")
```
### Perform a one-sample, two-tailed Wilcoxon signed-rank test
```{r}
wilcox.test(fishlength, mu=20, alternative = "two.sided")
```
1st line: give a warning (not an error) message regarding the implementation of this test. This can be safely ignored in this case as the p-value is so small, but essentially, it’s letting you know that some of the data values are identical to each other.
2nd line: name of test 
3rd line: dataset
The 4th line contains the two key outputs from the test:
  - The calculated statistic is 67.5 (we’ll need this for reporting)
  - The p-value is 0.001222.
The 5th line simply states the alternative hypothesis.

So, in this case since our p-value is less than 0.05 we can reject our null hypothesis and state that:

A one-sample Wilcoxon signed-rank test indicated that the median body length of male guppies (μ=18.8mm) differs significantly from 20mm (V=67.5, n=29, p=0.0012).

Whilst there are formal statistical tests for symmetry we will opt for a simple visual inspection using both a boxplot and a histogram

### Plot a histogram and boxplot of the data
```{r}
hist(fishlength, breaks=10)

boxplot(fishlength)
```
Here we can see that whilst the distribution isn’t perfectly symmetric, neither is it heavily skewed to the left or right and we can make the call that the distribution is “symmetric enough” for us to be happy with the results of the test.

## 4 Two-sample tests

### 4.1 Purpose and Aim

These tests are used when we have two samples of continuous data where we are trying to find out if the samples came from the same parent distribution or not. This essentially boils down to finding out if there is a difference in the means of the two samples.

### 4.2 Choosing a test

There are five key tests that can be used to deal with two samples. Choosing which test to use depends upon which key assumptions are satisfied by your sample data and this effectively boils down to answering four questions about your samples:
1. Are the samples normally distributed? (Yes/No)
2. How big are your samples? (<30 data points or >30 data points)
3. Are the samples paired? (Yes/No)
4. Do the samples have the same variance? (Yes/No)

There are two sets of tests to consider depending on your answers to questions 1 and 2. If your data are normally distributed or if you have big samples then you need to look at the parametric tests. If your data are not normally distributed and your sample size is small, then you need to look at non-parametric tests. 

Big data set - normally distributed or not, use a parametric test
Small data set - normally distributed use parametric, not normally distributed use non-parametric test

PARAMETRIC TESTS:

Paired sample = yes > paired t-test with equal variances yes or no
Paired sample = no > Equal variances = yes, students t-test; equal variance = no, Welch's t-test

NON-PARAMETRIC TESTS:

Paired sample = yes > wilcoxons signed rank test with equal variance yes or no
Paired sample = no > equal variances = yes, Mann-Whitney U test, equal variances = no, difficult resampling techniques might be only option

1. Testing whether a sample comes from a normal distribution was covered in the previous section. You need to visualise your data and/or use the Shapiro-Wilk test.
2. The size of the sample makes things easier. Because of maths (specifically due to something called the central limit theorem which I am not even going to attempt to touch upon here) if you have large samples then you can use the tests that assume normality of the parent population (Student’s t-test, Welch’s t-test and the paired t-test) even if your parent populations are certainly not normal. If you really want to understand exactly why this works, then you will have to do some more rigorous mathematics. So, for the moment I’m going to say that it’s ok to take these facts on faith and just trust me on this.
3. Paired samples mean that for every data point in one sample there is a matching data point in the other sample that is linked to it in some inextricable way. A typical example would involve a group of 20 test subjects being measured before and after some experiment. Providing that the experiment didn’t do anything fatal to the test subjects then the data would consist of two samples; 20 pre-experiment measurements and 20 post-experiment measurements. However, because the same test subjects were used then each pre-experiment data point can be matched exactly to one of the post-experiment data points. In this sense the two samples are said to be “paired”.
4. There are a couple of tests (Bartlett’s test and Levene’s test) that can be used to see if two samples come from distributions with the same variance. These will be covered in a later section.
5. Resampling techniques aren’t covered in this course and require a mixture of statistical understanding and programming skill. Ask a demonstrator (or Google it ) if you want to know more.

## 4.2.1 For two samples the data can be stored in one of three formats in R:
* as two separate vectors,
* in a stacked data frame,
* or in an unstacked data frame/list.

Two separate vectors case is (hopefully) obvious.

__Stacked form__ is where the data is arranged in 2 columns with one column containing all of the values and the other column is a factor containing a categorical variable. i.e. if we consider a dataset containing meerkat weights (in g) from two different locations then a stacked format for the data would look like: Weight (514, 568....) and location (Botswana, Uganda etc) Whereas an __unstacked__ format would have each sample placed in seperate columns: Botswana (514, 568..) and Uganda 

Stacked format is often the best format for the R to handle and I would encourage you all to start adopting this format as standard for data processing. Unstacked formats and separate vectors are easier to deal with as a human however and so I can understand if you prefer to start with your data in this format too.

## 4.3.1 Section commands

'unstack()'  *converts a stacked dataframe into an unstacked dataframe (or a list if the lengths of the samples are different*
'bartlett.test ()'  *performs bartlett's test for equality of variance*
'leveneTest()'  *performs Levene's test for equality of variance*

## 4.3.2 Data and Hypotheses

For example, suppose we now measure the body lengths of male guppies (in mm) collected from two rivers in Trinidad; the Aripo and the Guanapo. We want to test whether the mean body length differs between samples. We form the following null and alternative hypotheses:
*H0: The mean body length does not differ between the two groups.( μA = μG)
*H1: The mean body length does differ between the two groups.( μA ≠ μG).

We use a two-sample, two-tailed t-test to see if we can reject the null hypothesis.
* We use a two-sample test because we now have two samples.
* We use a two-tailed t-test because we want to know if our data suggest that the true (population) means are different from one another rather than that one mean is specifically bigger or smaller than the other.
* We’re using Student’s t-test because the sample sizes are big and because we’re assuming that the parent populations have equal variance (We can check this later).

### Read CS1-twosample.csv into R
```{r}
rivers<-read.csv(file='CS1-twosample.csv', header=T)
aggregate(length~river, data=rivers, summary) #Splits the data into subsets, computes summary statistics for each, and returns the result in a convenient form.
```

## 4.3.3 Visualise data
```{r}
boxplot(length~river, data=rivers, main="Male Guppies", ylab = "Length (mm)")
```

## 4.3.4 Perform a two-sample, two-tailed, t-test
```{r}
t.test(length~river, data=rivers, alternatives="two-sided", var.equal=TRUE)
```

In this case, with the data in stacked format:
*The first argument must be in the formula format: variables~category.
*The second argument must be the name of the data frame.
*The third argument gives the type of alternative hypothesis and must be one of “two.sided”, “greater” or “less”.
*The fourth argument says whether the variance of the two samples can be assumed to be equal. This makes it a Student’s t-test rather than a Welch’s t-test.

This next section shows you that we can perform exactly the same test with the data in a different (unstacked) format. This is potentially somewhat redundant (or thorough depending on your point of view). Probably best just to do it anyway just in case you gain extra insight through repetition. 

### Convert data to unstacked format and repeat the t-test
```{r}
uns.rivers<-unstack(rivers)
uns.rivers
```
In this case, with the data in unstacked format:
*The first two arguments must be vectors containing the numerical data for both samples.
*The third argument gives the type of alternative hypothesis and must be one of “two.sided”, “greater” or “less”.
*The fourth argument says whether the variance of the two samples can be assumed to be equal.

### Perform t-test with unstacked data (list)
```{r}
t.test(uns.rivers$Guanapo, uns.rivers$Aripo, alternative="two.sided", var.equal = TRUE)
```
The 1st line gives the name of the test and the 2nd line reminds you what the dataset was called, and what variables were used.
The 3rd line contains the three key outputs from the test:
*The calculated t-value is 3.8433 (we need this for reporting)
*There are 66 degrees of freedom (we need this for reporting)
*The p-value is 0.0002754.
The 4th line simply states the alternative hypothesis in terms of the difference between the two sample means (testing if the two sample means are different is equivalent to testing whether the difference in the means is equal to zero).
The 5th and 6th lines give the 95th confidence interval (we don’t need to know this here).
The 7th, 8th and 9th lines give the sample means for each group (20.33077 in Aripo and 18.29655 in Guanapo) which we found earlier.

Again, the p-value on the 3rd line is what we’re most interested in. Since the p-value is very small (much smaller than the standard significance level) we choose to say “that it is very unlikely that these two samples came from the same parent distribution and as such we can reject our null hypothesis and state that:

__A Student’s t-test indicated that the mean body length of male guppies in the Guanapo river (18.29mm) differs significantly from the mean body length of male guppies in the Aripo river(20.33mm) (t=3.8433, df=66, p=0.0003).__

## 4.3.6 Assumptions

In order to use a Student’s t-test (and for the results to be strictly valid) we have to make three assumptions:
1. The parent distributions from which the samples are taken are both normally distributed (which would lead to the sample data being normally distributed too).
2. Each data point in the samples is independent of the others.
3. The parent distributions should have the same variance.

In this example the first assumption can be ignored as the sample sizes are large enough (because of maths). If the samples were smaller then we would use the tests from the previous section.

The second point we can do nothing about unless we know how the data were collected, so again we ignore it.

The third point regarding equality of variance can be tested using either Bartlett’s test (if the samples are normally distributed) or Levene’s test (if the samples are not normally distributed). This is where it gets a bit trickier. Although we don’t care if the samples are normally distributed for the t-test to be valid (because the sample size is big enough to compensate), we do need to know if they are normally distributed in order to decide which variance test to use. 

### Perform a shapiro-wilk test on both samples seperately
```{r}
shapiro.test(uns.rivers$Guanapo)
shapiro.test(uns.rivers$Aripo)
```
We can see that whist the Guanapo data is probably normally distributed (p=0.1764 > 0.05), the Aripo data is unlikely to be normally distributed (p=0.02802 < 0.05). Remember that the p-value gives the probability of observing each sample if the parent population is actually normally distributed.
The Shapiro-Wilk test is quite sensitive to sample size. This means that if you have a large sample then even small deviations from normality will cause the sample to fail the test, whereas smaller samples are allowed to pass with much larger deviations. Here the Aripo data has nearly 40 points in it compared with the Guanapo data and so it is much easier for the Aripo sample to fail compared with the Guanapo data.

### Plot Q-Q plots for both samples
```{r}
qqnorm(uns.rivers$Guanapo, main = "Guanapo")
qqline(uns.rivers$Guanapo)
qqnorm(uns.rivers$Aripo, main = "Aripo")
qqline(uns.rivers$Aripo)
```
Remember that statistical tests do not provide answers, they merely suggest patterns. Human interpretation is still a crucial aspect to what we do.Nevertheless, the Shapiro-Wilk test has shown that the data are not normal “enough” and so in order to test for equality of variance we will use Levene’s test.
Levene’s test is not included in the default R packages and may require the installation of an additional package called car (Companion to Applied Regression).

### Perform levenes test
```{r}
library(car)
leveneTest(length~river, data=rivers)
```
The key bit of information is the 3rd line under the text “Pr(>F)”. This is the p-value (0.1876) for this test. And this tells us the probability of observing these two samples if they come from distributions with the same variance. As this probability is greater than our arbitrary significance level of 0.05 then we can be somewhat confident that the necessary assumptions for carrying out Student’s t-test on these two samples was valid.

For information only,if we had wanted to carry out Bartlett’s test (i.e. if the data had been sufficiently normally distributed) then the command would have been:

### Perform Bartlett test
```{r}
bartlett.test(length~river, data=rivers)
```
## 4.4 Mann-Whitney U test

This test also compares two samples, however for this test (in contrast to Student’s t-test) we don’t have to assume that the parent distributions are normally distributed. In order to compare the medians of the two groups we do still need the parent distributions (and consequently the samples) to both have the same shape and variance. In this test we look to see if the medians of the two parent distributions differ significantly from each other.
4.4.1 Section Commands - No new commands used in this section.

4.4.2 Data and Hypotheses

Again, we use the rivers dataset. We want to test whether the median body length of male guppies differs between samples. We form the following null and alternative hypotheses:
*H0: The difference in median body length between the two groups is 0.( μA - μG = 0)
*H1: The difference in median body length between the two groups is not 0.( μA - μG ≠ 0)
We use a two-tailed Mann-Whitney U test to see if we can reject the null hypothesis.

### Perform Mann-Whitney U test 
```{r}
wilcox.test(length~river, data=rivers, alternative="two.sided")
```
In this case, with the data in stacked format:
*The first argument must be in the formula format: variables~category.
*The second argument must be the name of the data frame.
*The third argument gives the type of alternative hypothesis and must be one of “two.sided”, “greater” or “less”.

The 1st line gives the name of the test and the 2nd line reminds you what the dataset was called, and what variables were used
The 3rd line contains the two key outputs from the test:
*The calculated W-value is 841 (we’ll use this in reporting)
*The p-value is 0.0006464.
The 4th line simply states the alternative hypothesis in terms of the difference between the two sample medians in that if there were a difference then one distribution would be shifted relative to the other.

Given that the p-value is less than 0.05 we can reject the null hypothesis at this confidence level.
Again, the p-value on the 3rd line is what we’re most interested in. Since the p-value is very small (much smaller than the standard significance level) we choose to say “that it is very unlikely that these two samples came from the same parent distribution and as such we can reject our null hypothesis and state that:

__A Mann-Whitney test indicated that the median body length of male guppies in the Guanapo river (18.8mm) differs significantly from the median body length of male guppies in the Aripo river(20.1mm) (W=841, p=0.0006).__

Again, as with the one-sample Wilcoxon signed-rank test, you may also see a warning message in your console output, this just means that some of the data points have exactly the same value which affects the internal mathematics slightly. However, given that the p-value is so very small, this is not something that we need to worry about.

## 4.5 Paired two-sample test

A paired t-test is used when we have two samples of continuous data that can be paired (examples of these sort of data would be weights of individuals before and after a diet). This test is applicable if the number of paired points within the samples is large (>30) or, if the number of points is small, then this test also works when the parent distributions are normally distributed.

## 4.5.1 Data and Hypotheses

For example, suppose we measure the cortisol levels in 20 adult females (nmol/l) first thing in the morning and again in the evening. We want to test whether the cortisol levels differs between the two measurement times. We will initially form the following null and alternative hypotheses:
*H0: There is no difference in cortisol level between times (μM = μE).
*H1: There is a difference in cortisol levels between times (μM ≠ μE).

We use a two-sample, two-tailed paired t-test to see if we can reject the null hypothesis.
*We use a two-sample test because we now have two samples.
*We use a two-tailed t-test because we want to know if our data suggest that the true (population) means are different from one another rather than that one mean is specifically bigger or smaller than the other.
*We use a paired test because each data point in the first sample can be linked to another data point in the second sample by a connecting factor.
*We’re using a t-test because we’re assuming that the parent populations are normal and have equal variance (We’ll check this in a bit).

```{r} 
cortisol <- read.csv(file='CS1-twopaired.csv',header=T)

```

### Summarise and visualise the data
```{r}
summary(cortisol)
boxplot(cortisol, vlab = "Level (nmol/l)" )
```
The box plot does not capture how the cortisol level of each individual subject has changed though. We can explore the individual changes between morning and evening by creating a boxplot of the differences between the two times of measurement.

```{r}
changeCor <- cortisol$evening - cortisol$morning
boxplot(changeCor, ylab="Change in cortisol (nmol/l)")
```
### Perform two-sample, two-tailed paired t-test
```{r}
t.test(cortisol$morning, cortisol$evening, alternative="two.sided", paired=T)
```
From our perspective the value of interested is on the 3rd line (p-value = 5.288x10-5). Given that this is substantially less than 0.05 we can reject the null hypothesis and state:

__A two-tailed, paired t-test indicated that the cortisol level in adult females differed significantly between the morning (313.5nmol/l) and the evening (197.4nmol/l) (t=-5.1833, df=19, p=5.3x10-5).__

## 4.6 Wilcoxon signed-rank test

A Wilcoxon signed-rank test is an alternative to a paired t-test. It does not require that the data are drawn from normal distributions, but it does require that the distribution of the differences is symmetric. We’re effectively testing to see if the median of the differences between the two samples differs significantly from zero.

4.6.1 Data and Hypotheses

Using the cortisol dataset from before we form the following null and alternative hypotheses:
*H0: The median of the difference in cortisol levels between the two groups is 0.(μM = μE)
*H1: The median of the difference in cortisol levels between the two groups is not 0.(μM≠μE)
We use a two-tailed Wilcoxon signed-rank test to see if we can reject the null hypothesis.

### Perform wilcoxon signed-rank test - cortisol
```{r}
wilcox.test(cortisol$morning, cortisol$evening, alternative= "two.sided", paired=T)
```
The first two arguments must be the two samples in numerical vector format.
The second argument gives the type of alternative hypothesis and must be one of “two.sided”, “greater” or “less”.
The third argument indicates that the test is paired.

The p value is given on the 3rd line (p-value = 0.0001678). Given that this is less than 0.05 we can still reject the null hypothesis.

__A two-tailed, Wilcoxon signed-rank test indicated that the median cortisol level in adult females differed significantly between the morning (320.5nmol/l) and the evening (188.9nmol/l) (V=197, p=0.00017).__